{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa2DBR2YoodxQX9au5xm/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricky-kiva/dl-deep-tf-cv-advanced/blob/main/1_l3_object_localization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Object Localization**\n",
        "\n",
        "- We'll *classify* an image & *localize* by drawing bounding boxes around it\n",
        "\n",
        "- We'll use MNIST dataset that is synthesized (modified) in terms of:\n",
        "\n",
        "  - Placing each \"digit\" randomly on 75x75 blank canvas\n",
        "\n",
        "- Note: the bounding box prediction can be modelled as *regression task*, means the model will predict a numeric value (as opposed to a category)"
      ],
      "metadata": {
        "id": "LXEMQzD_tfcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "7Cv76MIjupsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PIL\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "I3j8z_DGurZ7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define visualization parameters"
      ],
      "metadata": {
        "id": "NLsvK_E9u8br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im_width = 75\n",
        "im_height = 75\n",
        "normalized_coordinates = True"
      ],
      "metadata": {
        "id": "aTFlYMG2vFpS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function: Draw bounding boxes on image array"
      ],
      "metadata": {
        "id": "PqYcw7y8vKri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes_on_image_array(img, boxes, color=[], thickness=1, box_str_list=()):\n",
        "  image_pil = PIL.Image.fromarray(img) # create image memory from array\n",
        "  rgbimg = PIL.Image.new(\"RGBA\", image_pil.size) # creates new image canvas with given mode & size\n",
        "  rgbimg.paste(image_pil) # paste image to the rgbimg canvas\n",
        "\n",
        "  draw_bounding_boxes_on_image(rgbimg, boxes, color, thickness, box_str_list)\n",
        "  return np.array(rgbimg)\n",
        "\n",
        "def draw_bounding_boxes_on_image(img, boxes, color=[], thickness=1, box_str_list=()):\n",
        "  boxes_shape = boxes.shape\n",
        "  if not boxes_shape:\n",
        "    return\n",
        "  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
        "    raise ValueError('Input must be of size [N, 4]')\n",
        "\n",
        "  for i in range(boxes_shape[0]):\n",
        "    draw_bounding_box_on_image(img, boxes[i, 1], boxes[i, 0], boxes[i, 3], boxes[i, 2],\n",
        "                               color[i], thickness, box_str_list[i])\n",
        "\n",
        "def draw_bounding_box_on_image(img, ymin, xmin, ymax, xmax, color='red', thickness=1, display_str=None, normalized_coordinates=True):\n",
        "  draw = PIL.ImageDraw.Draw(img)\n",
        "  im_width, im_height = img.size\n",
        "\n",
        "  if normalized_coordinates:\n",
        "    (left, right, top, bottom) = ((xmin * im_width), (xmax * im_width),\n",
        "                                  (ymin * im_height), (ymax * im_height))\n",
        "  else:\n",
        "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
        "\n",
        "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),(left, top)],\n",
        "            width=thickness,\n",
        "            fill=color)"
      ],
      "metadata": {
        "id": "uq4u4WXAvPbP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set *Matplotlib* config"
      ],
      "metadata": {
        "id": "LIOkvqLH2I-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc('image', cmap='gray')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")"
      ],
      "metadata": {
        "id": "PQmYAG3x2PDc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function: Dataset to *Numpy* utilities"
      ],
      "metadata": {
        "id": "V6h8IOXv2ToU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pull 1 batch from the dataset\n",
        "def dataset_to_numpy(train_dataset, validation_dataset, N):\n",
        "\n",
        "  # Unbatch & re-batch train dataset, with a new batch size of `N`\n",
        "  batch_train_ds = train_dataset.unbatch().batch(N)\n",
        "\n",
        "  if tf.executing_eagerly():\n",
        "    for validation_digits, (validation_labels, validation_bboxes) in validation_dataset:\n",
        "      validation_digits = validation_digits.numpy()\n",
        "      validation_labels = validation_labels.numpy()\n",
        "      validation_bboxes = validation_bboxes.numpy()\n",
        "      break\n",
        "\n",
        "    for train_digits, (train_labels, train_bboxes) in batch_train_ds:\n",
        "      train_digits = train_digits.numpy()\n",
        "      train_labels = train_labels.numpy()\n",
        "      train_bboxes = train_bboxes.numpy()\n",
        "      break\n",
        "\n",
        "  validation_labels = np.argmax(validation_labels, axis=1)\n",
        "  train_labels = np.argmax(train_labels, axis=1)\n",
        "\n",
        "  return (train_digits, train_labels, train_bboxes,\n",
        "          validation_digits, validation_labels, validation_bboxes)\n",
        "\n",
        "# TODO: `create_digits_from_local_fonts()`, `display_digits_width_boxes()`, & `plot_metrics()`"
      ],
      "metadata": {
        "id": "tYjEGIkn2uuz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect hardware for deciding *Distribution Strategies*\n",
        "\n",
        "Note:\n",
        "- If TPU is available, use TPU Strategy. Otherwise:\n",
        "  - If `> 1` GPU is available, use Mirrored Strategy\n",
        "  - If only `1` GPU / CPU is available, use Default Strategy"
      ],
      "metadata": {
        "id": "u0Mius5q74dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")"
      ],
      "metadata": {
        "id": "IW2mzL7V8nUl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select *Distribution Strategy*"
      ],
      "metadata": {
        "id": "cevBG_hO87mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print('Running on TPU', tpu.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "  print('Running on single GPU', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "  print('Running on CPU')\n",
        "\n",
        "print('Number of accelerators:', strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PjWFZeD8-iK",
        "outputId": "eedb265f-2c63-400c-d47f-5b80c4b291d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CPU\n",
            "Number of accelerators: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define *Global Batch Size* parameter\n",
        "\n",
        "Note:\n",
        "- Global batch size will be shared across all replicas by *tf.data.Dataset API*\n",
        "- Single TPU has 8 cores, means 8 replicas of the model will be distributed to each core\n",
        "- Best practice is to scale the batch size by the number of replicas (*Learning rate* should be increased as well)"
      ],
      "metadata": {
        "id": "Q3La4Gtr-Lus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOCAL_BATCH_SIZE = 64\n",
        "GLOBAL_BATCH_SIZE = LOCAL_BATCH_SIZE * strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "OdlNCb3H_tcO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO"
      ],
      "metadata": {
        "id": "5GCwScbeK-FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create_digits_from_local_fonts()\n",
        "# display_digits_with_boxes()\n",
        "# plot_metrics()"
      ],
      "metadata": {
        "id": "k3bY8yrmLAtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function: Transform each images by pasting it on 75x75 canvas at random location"
      ],
      "metadata": {
        "id": "vOIjUJCNLQzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image_tfds(img, label):\n",
        "  # get random integers from 'uniform distribution'\n",
        "  # uniform distribution: (where every outcome has an equal chance of happening)\n",
        "  # `()` in `shape` param. denotes a scalar / tensor with zero dimensions (essentially, single number)\n",
        "  # params: (shape, minval, maxval, dtype)\n",
        "  # `48` max padding got from \"canvas - image_shape + 1 (0)\" (75-28)\n",
        "  xmin = tf.random.uniform((), 0, 48, dtype=tf.int32) # decide left padding\n",
        "  ymin = tf.random.uniform((), 0, 48, dtype=tf.int32) # decide top padding\n",
        "  img = tf.reshape(img, (28, 28, 1)) # reshape dataset image to shape (28,28) with single color channel\n",
        "\n",
        "  # params: (image, offset_height, offset_width, target_height, target_width)\n",
        "  img = tf.image.pad_to_bounding_box(img, ymin, xmin, 75, 75) # pad image with zeros to 'specified offset' until 'target dimension'\n",
        "  img = tf.cast(img, tf.float32) / 255.0 # cast tensor to a float\n",
        "\n",
        "  # find 'normalized' max & min coordinates (normalization makes it consistent regardless of the actual size of the canvas or image)\n",
        "  xmax = (xmin + 28) / 75\n",
        "  ymax = (ymin + 28) / 75\n",
        "  xmin = xmin / 75\n",
        "  ymin = ymin / 75\n",
        "\n",
        "  # `one_hot` convert label as list where one element is \"hot\" (set to 1) & the rest are \"cold\" (set to 0)\n",
        "  # - ex: tf.one_hot(3, 10) -> [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "  return img, (tf.one_hot(label, 10), [xmin, ymin, xmax, ymax])\n",
        "# ..."
      ],
      "metadata": {
        "id": "UdHySOg1LfMJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function: Get train dataset"
      ],
      "metadata": {
        "id": "6KsVedryO3st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def get_train_dataset():\n",
        "  # specify the operation inside this block will be distributed according to `strategy`\n",
        "  with strategy.scope():\n",
        "    # loads train MNIST dataset\n",
        "    # `as_supervised`: dataset is returned in format (input, label) pairs\n",
        "    # - Supervised Learning: train AI model in input-label manners\n",
        "    # `try_gcs` will try to load dataset from Google Cloud Storage (GCS) if it's not available locally\n",
        "    dataset = tfds.load('mnist', split='train', as_supervised=True, try_gcs=True)\n",
        "\n",
        "    # applies function `read_image_tfds()` to each element in the dataset\n",
        "    # `num_parallel_calls=16`: process up to 16 elements in parallel\n",
        "    dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
        "\n",
        "    # params: (buffer size, reshuffle_each_iteration)\n",
        "    # `reshuffle_each_iteration`: if `.repeat()` executed, dataset will be shuffled again\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True) # take first '5000' data, put into buffer, & randomly shuffle the data\n",
        "\n",
        "    # MANDATORY FOR KERAS\n",
        "    # repeats indefinitely. ensure dataset doesn't run out of data when training\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "    # groups dataset elements into batches of size GLOBAL_BATCH_SIZE\n",
        "    # `drop_remainder=True`: ensures all batches have same fixed size\n",
        "    # - important for training using TPU\n",
        "    dataset = dataset.batch(GLOBAL_BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "    # fetch (prepare) next batches while processing current batches\n",
        "    # params: (buffer_size). `-1` allows Tensorflow to automatically tune prefetch 'buffer size'\n",
        "    dataset = dataset.prefetch(-1)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "lHuFJbw7O6-v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function: Get validation dataset"
      ],
      "metadata": {
        "id": "9uva7k4sK3Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_validation_dataset():\n",
        "  dataset = tfds.load('mnist', split='test', as_supervised=True, try_gcs=True)\n",
        "  dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
        "\n",
        "  # why `batch()` first before `repeat()` in validation?\n",
        "  # - `batch()` sets the size of each step of validation\n",
        "  # - `repeat()` allows multiple epochs of validation without manual intervention\n",
        "  dataset = dataset.batch(10000, drop_remainder=True)\n",
        "  dataset = dataset.repeat() # MANDATORY FOR KERAS\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "53Rijwd-K6VM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate dataset"
      ],
      "metadata": {
        "id": "J6GakjTHOoRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  train_dataset = get_train_dataset()\n",
        "  validation_dataset = get_validation_dataset()"
      ],
      "metadata": {
        "id": "T5JDtgAFOpYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}