{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORQUK/a8sfnuTcpGz6gDJn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricky-kiva/dl-deep-tf-cv-advanced/blob/main/1_l3_object_localization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Object Localization**\n",
        "\n",
        "- We'll *classify* an image & *localize* by drawing bounding boxes around it\n",
        "\n",
        "- We'll use MNIST dataset that is synthesized (modified) in terms of:\n",
        "\n",
        "  - Placing each \"digit\" randomly on 75x75 blank canvas\n",
        "\n",
        "- Note: the bounding box prediction can be modelled as *regression task*, means the model will predict a numeric value (as opposed to a category)"
      ],
      "metadata": {
        "id": "LXEMQzD_tfcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "7Cv76MIjupsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PIL\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "I3j8z_DGurZ7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define visualization parameters"
      ],
      "metadata": {
        "id": "NLsvK_E9u8br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im_width = 75\n",
        "im_height = 75\n",
        "normalized_coordinates = True"
      ],
      "metadata": {
        "id": "aTFlYMG2vFpS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function: Draw bounding boxes on image array"
      ],
      "metadata": {
        "id": "PqYcw7y8vKri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes_on_image_array(img, boxes, color=[], thickness=1, box_str_list=()):\n",
        "  image_pil = PIL.Image.fromarray(img) # create image memory from array\n",
        "  rgbimg = PIL.Image.new(\"RGBA\", image_pil.size) # creates new image canvas with given mode & size\n",
        "  rgbimg.paste(image_pil) # paste image to the rgbimg canvas\n",
        "\n",
        "  draw_bounding_boxes_on_image(rgbimg, boxes, color, thickness, box_str_list)\n",
        "  return np.array(rgbimg)\n",
        "\n",
        "def draw_bounding_boxes_on_image(img, boxes, color=[], thickness=1, box_str_list=()):\n",
        "  boxes_shape = boxes.shape\n",
        "  if not boxes_shape:\n",
        "    return\n",
        "  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
        "    raise ValueError('Input must be of size [N, 4]')\n",
        "\n",
        "  for i in range(boxes_shape[0]):\n",
        "    draw_bounding_box_on_image(img, boxes[i, 1], boxes[i, 0], boxes[i, 3], boxes[i, 2],\n",
        "                               color[i], thickness, box_str_list[i])\n",
        "\n",
        "def draw_bounding_box_on_image(img, ymin, xmin, ymax, xmax, color='red', thickness=1, display_str=None, normalized_coordinates=True):\n",
        "  draw = PIL.ImageDraw.Draw(img)\n",
        "  im_width, im_height = img.size\n",
        "\n",
        "  if normalized_coordinates:\n",
        "    (left, right, top, bottom) = ((xmin * im_width), (xmax * im_width),\n",
        "                                  (ymin * im_height), (ymax * im_height))\n",
        "  else:\n",
        "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
        "\n",
        "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),(left, top)],\n",
        "            width=thickness,\n",
        "            fill=color)"
      ],
      "metadata": {
        "id": "uq4u4WXAvPbP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set *Matplotlib* config"
      ],
      "metadata": {
        "id": "LIOkvqLH2I-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc('image', cmap='gray')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")"
      ],
      "metadata": {
        "id": "PQmYAG3x2PDc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function: Dataset to *Numpy* utilities"
      ],
      "metadata": {
        "id": "V6h8IOXv2ToU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pull 1 batch from the dataset\n",
        "def dataset_to_numpy_util(train_dataset, validation_dataset, N):\n",
        "\n",
        "  # get 1 batch from each: 10.000 validation digits, N training digits\n",
        "  batch_train_ds = train_dataset.unbatch().batch(N)\n",
        "\n",
        "  if tf.executing_eagerly():\n",
        "    for validation_digits, (validation_labels, validation_bboxes) in validation_dataset:\n",
        "      validation_digits = validation_digits.numpy()\n",
        "      validation_labels = validation_labels.numpy()\n",
        "      validation_bboxes = validation_bboxes.numpy()\n",
        "      break\n",
        "\n",
        "    for train_digits, (train_labels, train_bboxes) in batch_train_ds:\n",
        "      train_digits = train_digits.numpy()\n",
        "      train_labels = train_labels.numpy()\n",
        "      train_bboxes = train_bboxes.numpy()\n",
        "      break\n",
        "\n",
        "  validation_labels = np.argmax(validation_labels, axis=1)\n",
        "  train_labels = np.argmax(train_labels, axis=1)\n",
        "\n",
        "  return (train_digits, train_labels, train_bboxes,\n",
        "          validation_digits, validation_labels, validation_bboxes)\n",
        "\n",
        "# TODO: `create_digits_from_local_fonts()`, `display_digits_width_boxes()`, & `plot_metrics()`"
      ],
      "metadata": {
        "id": "tYjEGIkn2uuz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect hardware for deciding *Distribution Strategies*\n",
        "\n",
        "Note:\n",
        "- If TPU is available, use TPU Strategy. Otherwise:\n",
        "  - If `> 1` GPU is available, use Mirrored Strategy\n",
        "  - If only `1` GPU / CPU is available, use Default Strategy"
      ],
      "metadata": {
        "id": "u0Mius5q74dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")"
      ],
      "metadata": {
        "id": "IW2mzL7V8nUl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select *Distribution Strategy*"
      ],
      "metadata": {
        "id": "cevBG_hO87mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print('Running on TPU', tpu.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "  print('Running on single GPU', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "  print('Running on CPU')\n",
        "\n",
        "print('Number of accelerators:', strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PjWFZeD8-iK",
        "outputId": "4883e87f-9a19-44a5-a0c8-ed4bd503947c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CPU\n",
            "Number of accelerators: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define ***Global** Batch Size* parameter\n",
        "\n",
        "Note:\n",
        "- Global batch size will be shared across all replicas by *tf.data.Dataset API*\n",
        "- Single TPU has 8 cores, means 8 replicas of the model will be distributed to each core\n",
        "- Best practice is to scale the batch size by the number of replicas (*Learning rate* should be increased as well)"
      ],
      "metadata": {
        "id": "Q3La4Gtr-Lus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOCAL_BATCH_SIZE = 64\n",
        "GLOBAL_BATCH_SIZE = LOCAL_BATCH_SIZE * strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "OdlNCb3H_tcO"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}